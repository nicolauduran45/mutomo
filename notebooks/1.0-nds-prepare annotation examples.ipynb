{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing annotation examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Example Data from the STI Unlabelled Dataset\n",
    "\n",
    "We begin by selecting a sample of research abstracts from the STI (Science, Technology, and Innovation) unlabelled dataset. This data will serve as the input for our information extraction pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220752</td>\n",
       "      <td>Enhancing innovation management capacities of ...</td>\n",
       "      <td>Enterprise Europe Network is a main support in...</td>\n",
       "      <td>project/european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2124685859</td>\n",
       "      <td>Mutual cooperative effects between single- and...</td>\n",
       "      <td>Two types of resonance between the spontaneous...</td>\n",
       "      <td>publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US 2012/0048877 W</td>\n",
       "      <td>SYSTEM AND METHOD FOR PERFORMING WELLBORE FRAC...</td>\n",
       "      <td>Methods for performing oilfield operations are...</td>\n",
       "      <td>patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2600571758</td>\n",
       "      <td>Sales Tax Competition among State–Local Govern...</td>\n",
       "      <td>ABSTRACTThis article estimates tax reaction fu...</td>\n",
       "      <td>publication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                              title  \\\n",
       "0             220752  Enhancing innovation management capacities of ...   \n",
       "1        W2124685859  Mutual cooperative effects between single- and...   \n",
       "2  US 2012/0048877 W  SYSTEM AND METHOD FOR PERFORMING WELLBORE FRAC...   \n",
       "3        W2600571758  Sales Tax Competition among State–Local Govern...   \n",
       "\n",
       "                                            abstract              type  \n",
       "0  Enterprise Europe Network is a main support in...  project/european  \n",
       "1  Two types of resonance between the spontaneous...       publication  \n",
       "2  Methods for performing oilfield operations are...            patent  \n",
       "3  ABSTRACTThis article estimates tax reaction fu...       publication  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset \n",
    "ds_dict = load_dataset(\"SIRIS-Lab/unlabelled-sti-corpus\")\n",
    "\n",
    "# get train split\n",
    "ds_train = ds_dict[\"train\"]\n",
    "\n",
    "# get 30 random exmaples\n",
    "df_sampled_examples = pd.DataFrame(ds_train.shuffle(seed=42))\n",
    "\n",
    "display(df_sampled_examples.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Annotate Each Example Using Two LLMs\n",
    "\n",
    "For each title and abstract, we will generate key information extractions using **two different language models (LLMs)**. Each model will produce its own structured output for the defined dimensions (motivations, objectives, methods, impact, and research topic). This provides options for downstream human annotation and quality comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base = '''Given the title and abstract of a research proposal, extract and summarize the following information in a clear, structured, and programmatically friendly JSON format:\n",
    "\n",
    "- **Motivations:**  \n",
    "  Provide a list of 1 to 3 clear and concise sentences summarizing the main motivations or problems addressed by the research. Each motivation should be independent and not reference others. Avoid redundancy—if motivations are similar, combine or rephrase for clarity.\n",
    "\n",
    "- **Objectives:**  \n",
    "  Provide a list of 1 to 3 clear and concise sentences summarizing the main objectives of the research. Each objective should be independent and not reference others. If two objectives are highly similar, combine them into a single sentence to avoid redundancy.\n",
    "\n",
    "- **Methods:**  \n",
    "  Provide a list of 1 to 3 clear and concise sentences summarizing the main methods, techniques, or approaches. Omit specific details such as sample sizes, participant numbers, and timeframes.\n",
    "\n",
    "- **Results:**  \n",
    "  Provide a list of 1 to 3 clear and concise sentences summarizing the main results, expected results or impact. Omit details such as sample sizes, participant numbers, and timeframes.\n",
    "\n",
    "- **Research Topic:**  \n",
    "  Summarize the central research topic as a single, concise phrase or sentence.\n",
    "\n",
    "**Formatting instructions:**  \n",
    "Return only the output as valid JSON, following this structure (with no additional explanation or text):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"motivations\": [\"First motivation here\", \"Second motivation here\", ...],\n",
    "  \"objectives\": [\"First research objective here\", \"Second research objective here\", ...],\n",
    "  \"methods\": [\"First research method here\", \"Second research method here\", ...],\n",
    "  \"results\": [\"First result/impact here\", \"Second result/impact here\", ...],\n",
    "  \"research_topic\": \"Specific research topic here\"\n",
    "}\n",
    "\n",
    "***Return only the JSON content, and nothing else.***\n",
    "\n",
    "-----------------\n",
    "Input:\n",
    "\n",
    "Title: \n",
    "Democratising and making sense out of heterogeneous scholarly content\n",
    "\n",
    "Abstract: \n",
    "SciLake's mission is to build upon the OpenAIRE ecosystem and EOSC services to (a) facilitate and empower the creation, interlinking and maintenance of Scientific/Scholarly Knowledge Graphs (SKGs) and the execution of data science and graph mining queries on top of them, (b) contribute to the democratization of scholarly content and the related added value services implementing a community-driven management approach, and (c) offer advanced, AI-assisted services that exploit customised perspectives of scientific merit to assist the navigation of the vast scientific knowledge space. In brief, SciLake will develop, support, and offer customisable services to the research community following a two-tier service architecture. First, it will offer a comprehensive, open, transparent, and customisable scientific data-lake-as-a-service (service tier 1), empowering and facilitating the creation, interlinking, and maintenance of SKGs both across and within different scientific disciplines. On top of that, it will build and offer a tier of customisable, AI-assisted services that facilitate the navigation of scholarly content following a scientific merit-driven approach (tier 2), focusing on two merit aspects which are crucial for the research community at large: impact and reproducibility. The services in both tiers will leverage advanced AI techniques (text and graph mining) that are going to exploit and extend existing technologies provided by SciLake's technology partners. Finally, to showcase the value of the provided services and their capability to address current and anticipated needs of different research communities, four scientific domains (neuroscience, cancer research, transportation, and energy) have been selected to serve as pilots. For each, the developed services will be customised, to accommodate differences in research procedures, practices, impact measures and types of research objects, and will be validated and evaluated through real-world use cases.\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"motivations\": [\n",
    "    \"Researchers face challenges in navigating, interlinking, and maintaining heterogeneous scholarly content, which limits the accessibility and usability of scientific knowledge.\",\n",
    "    \"There is a need for democratized access and advanced tools to analyze and evaluate scholarly content based on scientific merit such as impact and reproducibility.\"\n",
    "  ],\n",
    "  \"objectives\": [\n",
    "    \"Facilitate the creation, interlinking, and maintenance of Scientific Knowledge Graphs across and within various scientific disciplines.\",\n",
    "    \"Develop and provide AI-assisted, customizable services to support navigation and analysis of scholarly content based on scientific merit.\",\n",
    "    \"Promote the democratization of scholarly content through a community-driven management approach.\"\n",
    "  ],\n",
    "  \"methods\": [\n",
    "    \"Implement a scientific data-lake-as-a-service to support the creation and maintenance of knowledge graphs.\",\n",
    "    \"Leverage advanced AI techniques, including text and graph mining, to enable enhanced navigation and analysis of scholarly content.\",\n",
    "    \"Customize and validate the developed services in pilot domains such as neuroscience, cancer research, transportation, and energy.\"\n",
    "  ],\n",
    "  \"results\": [\n",
    "    \"Empower researchers with effective tools to navigate, analyze, and utilize scholarly content.\",\n",
    "    \"Enhance the reproducibility and impact assessment of scientific research.\",\n",
    "    \"Support diverse research communities through tailored AI-driven services and promote wider access to scientific knowledge.\"\n",
    "  ],\n",
    "  \"research_topic\": \"Democratization and advanced analysis of heterogeneous scholarly content using AI and knowledge graphs\"\n",
    "}\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import openai\n",
    "from together import Together\n",
    "import anthropic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['TOGETHER_AI']\n",
    "\n",
    "# Directory to store interim results\n",
    "os.makedirs(\"../data/interim/pseodoannotation\", exist_ok=True)\n",
    "interim_dir = \"../data/interim/pseodoannotation\"\n",
    "\n",
    "llama_client = Together(api_key=os.environ['TOGETHER_AI'])\n",
    "openai_client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "anthropic_client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "def extract_json(text):\n",
    "    json_match = re.search(r'```json(.*?)```', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1).strip()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"No JSON block found.\")\n",
    "    return None\n",
    "\n",
    "for i, row in tqdm(df_sampled_examples.iterrows(), total=len(df_sampled_examples)):\n",
    "    id = row['id']\n",
    "    interim_path = os.path.join(interim_dir, f\"{id}.json\")\n",
    "    if os.path.exists(interim_path):\n",
    "        # Skip if this example is already processed\n",
    "        continue\n",
    "\n",
    "    title = row['title']\n",
    "    abstract = row['abstract'].replace('\\n', ' ').replace('  ', ' ')\n",
    "    prompt = f\"\"\"{prompt_base}\n",
    "-----------------\n",
    "Title:\n",
    "{title}\n",
    "\n",
    "Abstract:\n",
    "{abstract}\"\"\"\n",
    "\n",
    "    # --- Llama call ---\n",
    "    llama_response = llama_client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.1,\n",
    "        top_p=0.1,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "        stream=False\n",
    "    )\n",
    "    llama_output = llama_response.choices[0].message.content\n",
    "\n",
    "    # --- OpenAI call ---\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful academic data assistant that extracts information from research documents.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=1500,\n",
    "    )\n",
    "    openai_output = openai_response.choices[0].message.content.strip()\n",
    "\n",
    "    # --- Anthropic (Claude) call ---\n",
    "    anthropic_response = anthropic_client.messages.create(\n",
    "        model=\"claude-opus-4-20250514\t\",  # or another claude-3 model if you prefer\n",
    "        max_tokens=1500,\n",
    "        temperature=0.1,\n",
    "        system=\"You are a helpful academic data assistant that extracts information from research documents.\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    # For Claude v3, output is in .content (as a list of message blocks)\n",
    "    anthropic_output = anthropic_response.content[0].text if hasattr(anthropic_response, \"content\") and anthropic_response.content else \"\"\n",
    "\n",
    "    # Extract JSON outputs\n",
    "    llama_json = extract_json(llama_output)\n",
    "    openai_json = extract_json(openai_output)\n",
    "    anthropic_json = extract_json(anthropic_output)\n",
    "\n",
    "    result = {\n",
    "        \"index\": i,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"llama_json\": llama_json,\n",
    "        \"openai_json\": openai_json,\n",
    "        \"anthropic_json\": anthropic_json,\n",
    "        \"llama_raw\": llama_output,\n",
    "        \"openai_raw\": openai_output,\n",
    "        \"anthropic_raw\": anthropic_output,\n",
    "    }\n",
    "\n",
    "    # Save each result as a JSON file\n",
    "    with open(interim_path, \"w\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Combine Results Later:\n",
    "import glob\n",
    "import json\n",
    "\n",
    "results = []\n",
    "for filename in sorted(glob.glob(\"../data/interim/pseodoannotation/*.json\")):\n",
    "    with open(filename, \"r\") as f:\n",
    "        results.append(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Push LLM Outputs to Argilla for Human Review\n",
    "\n",
    "Both sets of LLM-generated annotations will be uploaded to **Argilla** as candidate suggestions. Annotators will review, choose, or edit the outputs, creating high-quality, human-verified annotations to build our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import argilla as rg\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def ensure_workspace(workspace_name=\"default\"):\n",
    "    # Ensure the workspace exists\n",
    "    existing_workspaces = client.workspaces.list()\n",
    "    if not any(ws.name == workspace_name for ws in existing_workspaces):\n",
    "        workspace = rg.Workspace(name=workspace_name)\n",
    "        client.workspaces.add(workspace)\n",
    "        logger.info(f\"Created new workspace: {workspace_name}\")\n",
    "    else:\n",
    "        logger.info(f\"Workspace '{workspace_name}' exists.\")\n",
    "\n",
    "# argilla settings\n",
    "URL = 'http://argilla2.unics.cloud/'\n",
    "KEY = os.getenv(\"ARGILLA\")\n",
    "\n",
    "client = rg.Argilla(api_url=URL, api_key=KEY)\n",
    "\n",
    "# create work space if it doesn't exist\n",
    "ARGILLA_WORKSPACE = 'mutomo'\n",
    "ensure_workspace(ARGILLA_WORKSPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_overlap = rg.TermsMetadataProperty(\n",
    "#     name=\"overlap_status\",\n",
    "#     options=[\"Partial overlap\", \"Total overlap\", \"Zero overlap\"],\n",
    "#     title=\"Model agreement\",\n",
    "#     visible_for_annotators=True,\n",
    "# )\n",
    "\n",
    "guidelines = '''# STI Document Classification Guidelines\n",
    "\n",
    "This task involves classifying science, technology, and innovation (STI)  documents (pubs, projects, and patents) according to the HORZION Clusters and Areas of Intervention and the SDGs.\n",
    "\n",
    "## Your Task\n",
    "\n",
    "For each grant, you will:\n",
    "1. Review the title and abstract\n",
    "2. Select the most adequate categories for the record (suggestions are provided to speed up the process and to generate debate)\n",
    "3. Optionally provide feedback on the classification criteria or the category definitions\n",
    "\n",
    "## Classification Categories\n",
    "https://docs.google.com/document/d/1WlSAu9rzs515uuNNQ0AiTtt8LsSWX_1in81tz86GMk8/edit?tab=t.0#heading=h.im41vt96h3g9\n",
    "'''\n",
    "\n",
    "metadata_doctype = rg.TermsMetadataProperty(\n",
    "    name=\"doctype\",\n",
    "    title=\"Type of document/source\",\n",
    "    visible_for_annotators=True,\n",
    ")\n",
    "\n",
    "metadata_id = rg.TermsMetadataProperty(\n",
    "    name=\"id\",\n",
    "    title=\"Document Id\",\n",
    "    visible_for_annotators=True,\n",
    ")\n",
    "\n",
    "# argilla dataset settings\n",
    "settings = rg.Settings(\n",
    "    guidelines=f\"{'HOLA!'}\",\n",
    "    fields=[\n",
    "        #rg.TextField(name=\"id\"),  # unique identifier for each record (metadata)\n",
    "        rg.TextField(name=\"title\"),  # title of the document (metadata)\n",
    "        rg.TextField(name=\"abstract\"),  # abstract of the document (metadata)\n",
    "        rg.TextField(name=\"responses\",use_markdown=True),  # justifications from the llm (metadata)\n",
    "\n",
    "    ],\n",
    "    questions=[\n",
    "        # multi-label question for llm suggested labels\n",
    "        rg.LabelQuestion(\n",
    "            name=\"motivations\",  \n",
    "            labels=['model-1','model-2','model-3','none'],  # replace with actual cluster labels\n",
    "            title='Motivations (choose the most accurate, if none, write your own)',\n",
    "            description=\"Choose the most accurate, if none, write your own.\",\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(name='motivations_feedback',\n",
    "                        title=\"If 'none' of the responses are helpful and cocrent, provie the response in bullet points\",\n",
    "                        required=False),\n",
    "        rg.LabelQuestion(\n",
    "            name=\"objectives\",  \n",
    "            labels=['model-1','model-2','model-3','none'],  # replace with actual cluster labels\n",
    "            title=\"Objectives (choose the most accurate, if none, write your own)\",\n",
    "            description=\"Choose the most accurate, if none, write your own.\",\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(name=\"objectives_feedback\",\n",
    "                        title='If none of the responses are helpful and cocrent, provie the response in bullet points',\n",
    "                        required=False),\n",
    "        rg.LabelQuestion(\n",
    "            name=\"methods\",  \n",
    "            labels=['model-1','model-2','model-3','none'],  # replace with actual cluster labels\n",
    "            title=\"Methods (choose the most accurate, if none, write your own)\",\n",
    "            description=\"Choose the most accurate, if none, write your own.\",\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(name=\"methods_feedback\",\n",
    "                        title='If none of the responses are helpful and cocrent, provie the response in bullet points',\n",
    "                        required=False),\n",
    "\n",
    "        rg.LabelQuestion(\n",
    "            name=\"results\",  \n",
    "            labels=['model-1','model-2','model-3','none'],  # replace with actual cluster labels\n",
    "            title=\"Results (choose the most accurate, if none, write your own)\",\n",
    "            description=\"Choose the most accurate, if none, write your own.\",\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(name=\"results_feedback\",\n",
    "                        title='If none of the responses are helpful and cocrent, provie the response in bullet points',\n",
    "                        required=False),\n",
    "\n",
    "        rg.LabelQuestion(\n",
    "            name=\"research-subject\",  \n",
    "            labels=['model-1','model-2','model-3','none'],  # replace with actual cluster labels\n",
    "            title=\"Research Subject (choose the most accurate, if none, write your own)\",\n",
    "            description=\"Choose the most accurate, if none, write your own.\",\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(name=\"research-subject_feedback\",\n",
    "                        title='If none of the responses are helpful and cocrent, provie the response in bullet points',\n",
    "                        required=False),\n",
    "        \n",
    "    ],\n",
    "    #suggestions =  [rg.Suggestion(\"Comments/Feedback\", \"default text\", agent=\"Majority Vote\")]\n",
    "    metadata=[metadata_id, metadata_doctype]#, metadata_overlap]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the argilla dataset\n",
    "dataset_name = \"mutomo\"\n",
    "# remove if exists\n",
    "#dataset_to_delete = client.datasets(name=dataset_name)\n",
    "\n",
    "dataset = rg.Dataset(name=dataset_name,\n",
    "                     settings=settings,\n",
    "                     client=client,\n",
    "                     workspace=ARGILLA_WORKSPACE\n",
    ")\n",
    "\n",
    "# check if dataset exists before creating\n",
    "try:\n",
    "    dataset.create()\n",
    "except Exception as e:\n",
    "    print(f\"Dataset already exists or cannot be created: {e}\")\n",
    "    dataset_to_delete = client.datasets(name=dataset_name, workspace=ARGILLA_WORKSPACE)\n",
    "    dataset_deleted = dataset_to_delete.delete()\n",
    "    dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Motivations\n",
      "\n",
      "- **model-1**\n",
      "  - There is a need for coordinated management and protection of biodiversity in Italian and Croatian coastal wetlands.\n",
      "  - There is a lack of public awareness about the value of wetlands ecosystems and the need for active engagement in territorial governance.\n",
      "\n",
      "- **model-2**\n",
      "  - There is a need for coordinated management and protection of coastal wetlands in the Italy-Croatia cross-border region to preserve biodiversity.\n",
      "  - Lack of public awareness about the value of wetland ecosystems hinders effective governance and conservation efforts.\n",
      "\n",
      "- **model-3**\n",
      "  - Coastal wetlands in the Italy-Croatia cross-border region lack coordinated management approaches, threatening biodiversity conservation.\n",
      "  - There is insufficient public awareness and engagement regarding the ecological value of wetland ecosystems among stakeholders and the general public.\n",
      "\n",
      "\n",
      "### Objectives\n",
      "\n",
      "- **model-1**\n",
      "  - Establish a cross-border observatory to monitor best practices and data on Italian and Croatian coastal wetlands.\n",
      "  - Implement a coordinated methodology for wetlands management to protect biodiversity.\n",
      "  - Share a cross-border strategy and strengthen synergies among Italian and Croatian coastal wetlands.\n",
      "  - Improve public awareness about the value of the wetlands ecosystems and strengthen their active engagement in territorial governance.\n",
      "\n",
      "- **model-2**\n",
      "  - Establish a cross-border Observatory to monitor best practices and data on Italian and Croatian coastal wetlands.\n",
      "  - Implement a coordinated methodology for wetlands management through the Wetland Contract to protect biodiversity.\n",
      "  - Enhance public awareness and engagement in territorial governance among stakeholders.\n",
      "\n",
      "- **model-3**\n",
      "  - Establish a cross-border Observatory to monitor best practices and data on Italian and Croatian coastal wetlands.\n",
      "  - Protect biodiversity through implementation of a coordinated wetland management methodology (Wetland Contract) and develop a shared cross-border strategy.\n",
      "  - Improve public awareness about wetland ecosystem values and strengthen stakeholder engagement in territorial governance.\n",
      "\n",
      "\n",
      "### Methods\n",
      "\n",
      "- **model-1**\n",
      "  - Setting up a cross-border observatory for monitoring best practices and data.\n",
      "  - Implementing a coordinated methodology for wetlands management, known as the Wetland Contract.\n",
      "  - Sharing a cross-border strategy and strengthening synergies among wetlands.\n",
      "  - Improving public awareness and engagement through various initiatives.\n",
      "\n",
      "- **model-2**\n",
      "  - Set up a cross-border Observatory to monitor and share data on coastal wetlands.\n",
      "  - Develop and implement a coordinated methodology for wetlands management.\n",
      "  - Share a cross-border strategy and strengthen synergies among Italian and Croatian coastal wetlands.\n",
      "\n",
      "- **model-3**\n",
      "  - Create a cross-border Observatory for monitoring and data collection on coastal wetlands.\n",
      "  - Implement a coordinated Wetland Contract methodology for integrated wetland management.\n",
      "  - Develop awareness campaigns and engagement activities targeting policy makers, managers, professionals, and the general public.\n",
      "\n",
      "\n",
      "### Results\n",
      "\n",
      "- **model-1**\n",
      "  - Improved management and protection of biodiversity in Italian and Croatian coastal wetlands.\n",
      "  - Increased public awareness and active engagement in territorial governance.\n",
      "  - Strengthened synergies among Italian and Croatian coastal wetlands.\n",
      "\n",
      "- **model-2**\n",
      "  - Improved protection and preservation of biodiversity in Italian and Croatian coastal wetlands.\n",
      "  - Enhanced public awareness and engagement in wetland conservation efforts.\n",
      "  - Strengthened synergies and coordination among stakeholders in the Italy-Croatia cross-border region.\n",
      "\n",
      "- **model-3**\n",
      "  - Enhanced protection of biodiversity in Italian and Croatian coastal wetlands through coordinated management.\n",
      "  - Strengthened cross-border cooperation and synergies in wetland conservation efforts.\n",
      "  - Increased public awareness and active stakeholder participation in wetland governance and protection.\n",
      "\n",
      "\n",
      "### Research_subject\n",
      "\n",
      "- **model-1**\n",
      "  - Coordinated Wetland Management in Italy-Croatia Cross Border Region\n",
      "\n",
      "- **model-2**\n",
      "  - Coordinated management and conservation of coastal wetlands in the Italy-Croatia cross-border region\n",
      "\n",
      "- **model-3**\n",
      "  - Cross-border coordinated management of coastal wetlands in the Italy-Croatia region\n",
      "\n",
      "\n",
      "Shuffle order: ['openai_json', 'llama_json', 'anthropic_json']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def markdown_aggregate_shuffled(row, dimensions=None, model_keys=None, seed=None):\n",
    "    if dimensions is None:\n",
    "        dimensions = [\"motivations\", \"objectives\", \"methods\", \"results\", \"research_subject\"]\n",
    "    if model_keys is None:\n",
    "        model_keys = [k for k in row.keys() if k.endswith(\"_json\")]\n",
    "\n",
    "    rnd = random.Random(seed)\n",
    "    shuffled_model_keys = model_keys.copy()\n",
    "    rnd.shuffle(shuffled_model_keys)\n",
    "\n",
    "    out = []\n",
    "    for dim in dimensions:\n",
    "        out.append(f\"### {dim.capitalize()}\\n\")\n",
    "        for i, mk in enumerate(shuffled_model_keys, start=1):\n",
    "            model_label = f\"model-{i}\"\n",
    "            model_data = row.get(mk) or {}  # Handle None by using empty dict\n",
    "            vals = model_data.get(dim, None)\n",
    "            out.append(f\"- **{model_label}**\")\n",
    "            if not vals:  # If None or empty, add a placeholder\n",
    "                out.append(\"  - *(empty)*\")\n",
    "            elif isinstance(vals, list):\n",
    "                for s in vals:\n",
    "                    out.append(f\"  - {s}\")\n",
    "            else:  # string or single value\n",
    "                out.append(f\"  - {vals}\")\n",
    "            out.append(\"\")  # Blank line for spacing\n",
    "        out.append(\"\")  # Blank line for next dimension\n",
    "    return \"\\n\".join(out), shuffled_model_keys\n",
    "\n",
    "# Example usage:\n",
    "md, shuffle_order = markdown_aggregate_shuffled(row, seed=42)\n",
    "print(md)\n",
    "print(\"Shuffle order:\", shuffle_order)  # Useful for mapping model-N back to real model if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for row in results:\n",
    "    doctype = df_sampled_examples.iloc[row['index']]['type']\n",
    "    docid = df_sampled_examples.iloc[row['index']]['id']\n",
    "    md, shuffle_order = markdown_aggregate_shuffled(row)\n",
    "    \n",
    "    suggestions = [rg.Suggestion(\"motivations_feedback\", \"default text\", agent=\"default\")]\n",
    "\n",
    "    record = rg.Record(\n",
    "            fields={\n",
    "                #\"id\": str(row['id']),\n",
    "                \"title\": row['title'],\n",
    "                \"abstract\": row['abstract'],\n",
    "                \"responses\": md#''#row['justification_output']\n",
    "            },\n",
    "            metadata={\n",
    "                \"id\": docid,\n",
    "                \"doctype\": doctype,\n",
    "                #'overlap_status': row['overlap_status']\n",
    "            },\n",
    "        suggestions=suggestions\n",
    "        )\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # Adjust based on server limits\n",
    "\n",
    "for i in range(0, len(records), batch_size):\n",
    "    try:\n",
    "        dataset.records.log(records[i:i+batch_size])\n",
    "        print(f\"✅ Uploaded batch {i // batch_size + 1} ({len(records[i:i+batch_size])} records)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to upload batch {i // batch_size + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Users</h3><table><tr><th>username</th><th>id</th><th>role</th><th>updated_at</th></tr><tr><td>argilla</td><td>7ee2325f-05b4-4d11-a4a3-07b5be8fc14d</td><td>owner</td><td>2025-01-09T09:51:02.614050</td></tr><tr><td>annotator_smart_cities</td><td>5593bf77-d9f0-4210-8676-58471ff82808</td><td>annotator</td><td>2025-01-28T13:03:35.266504</td></tr><tr><td>annotator_ict</td><td>440e7203-81fd-4f53-b899-fdfd727af6fe</td><td>annotator</td><td>2025-01-28T13:08:26.425012</td></tr><tr><td>annotator_smart_buildings</td><td>f49deb3c-75a2-4056-9e90-df4ce77791e3</td><td>annotator</td><td>2025-01-28T13:08:26.875474</td></tr><tr><td>annotator_circular_economy</td><td>bc60a264-bada-46de-b0f0-b0c2712c2c3f</td><td>annotator</td><td>2025-01-28T13:08:27.282235</td></tr><tr><td>annotator_sustainable_food</td><td>32b0dcc3-cda7-46f0-b2d3-099a526dc1fc</td><td>annotator</td><td>2025-01-28T13:08:27.692671</td></tr><tr><td>annotator_sustainable_tourism</td><td>c9a9d53c-67de-4ae3-a09e-25bf86ff2518</td><td>annotator</td><td>2025-01-28T13:08:28.097751</td></tr><tr><td>annotator_health_medicine</td><td>494668b1-f973-47b4-85bc-0a1e4e01347c</td><td>annotator</td><td>2025-01-28T13:08:28.509356</td></tr><tr><td>annotator_mobility</td><td>344987ea-3a5b-4fd1-83a2-f33131668f85</td><td>annotator</td><td>2025-01-28T13:08:28.919467</td></tr><tr><td>annotator_materials_end_products</td><td>4e99a761-5f33-49fb-b8c2-64ca826f557f</td><td>annotator</td><td>2025-01-28T13:08:29.330462</td></tr><tr><td>annotator_factories_future</td><td>37171b26-5c2c-45dc-960e-dfdd91064a22</td><td>annotator</td><td>2025-01-28T13:08:31.389856</td></tr><tr><td>natalija.pos@gov.si</td><td>f3a2e4af-ecb3-4238-a645-9617e6ca50cb</td><td>annotator</td><td>2025-01-28T13:16:51.680620</td></tr><tr><td>joze.petkovsek@gov.si</td><td>3faf5831-b1ce-4bbd-a1cc-485875df91dc</td><td>annotator</td><td>2025-01-28T13:16:52.013894</td></tr><tr><td>gorazd.jenko@gov.si</td><td>9a232100-7575-41d4-801a-38901ce4e892</td><td>annotator</td><td>2025-01-28T13:16:52.349793</td></tr><tr><td>matej.forte@gov.si</td><td>571ac0fc-39dc-4385-a177-fedf20a7a0b7</td><td>annotator</td><td>2025-01-28T13:16:52.634364</td></tr><tr><td>peter.medica@gov.si</td><td>392780d2-3585-4064-a2b0-1fbaf325903d</td><td>annotator</td><td>2025-01-28T13:16:53.064600</td></tr><tr><td>bojan.suvorov@gov.si</td><td>9ba54423-98b8-477a-86f1-c42b7b13e6db</td><td>annotator</td><td>2025-01-28T13:16:53.370299</td></tr><tr><td>marko.hren@gov.si</td><td>bc82cbb4-a951-4a85-bde0-da767ee846ed</td><td>annotator</td><td>2025-01-28T13:16:55.600297</td></tr><tr><td>nicandro.bovenzi@sirisacademic.com</td><td>bcb2098a-032f-4688-9bc8-5001d1d3dfc3</td><td>annotator</td><td>2025-02-13T14:36:30.799675</td></tr><tr><td>eleonora.fabbri@sirisacademic.com</td><td>01234c1c-57d3-4ca4-8c86-86ddc6201372</td><td>annotator</td><td>2025-02-13T14:36:31.654300</td></tr><tr><td>carolina.carmo@sirisacademic.com</td><td>a70ee779-e63d-4cd7-aa7c-98bf8baf3414</td><td>annotator</td><td>2025-02-13T14:36:32.253805</td></tr><tr><td>berta.grimau@sirisacademic.com</td><td>a70cce8f-afa7-4be9-b122-efb0ba610105</td><td>annotator</td><td>2025-02-13T14:36:32.897923</td></tr><tr><td>adria.plazas@sirisacademic.com</td><td>1f8aa2e7-ff43-4475-8eb0-9e0e4af5e910</td><td>annotator</td><td>2025-02-13T14:36:33.635385</td></tr><tr><td>sonia.veiga@sirisacademic.com</td><td>d99de26a-49b3-4529-ac66-99ea580f0959</td><td>annotator</td><td>2025-02-13T14:36:34.262006</td></tr><tr><td>pablo.accuosto@sirisacademic.com</td><td>d8098014-e08b-4370-b56b-a8b99f2e1732</td><td>annotator</td><td>2025-02-13T14:36:34.941444</td></tr><tr><td>matthias.heuser@sirisacademic.com</td><td>362cdafc-0faa-441a-9242-9b5a354f01fe</td><td>annotator</td><td>2025-03-27T15:07:47.628854</td></tr><tr><td>zofia.sawicka@sirisacademic.com</td><td>c681ea26-b930-4cb3-9be9-9f1d47b33d84</td><td>annotator</td><td>2025-03-27T15:07:48.135767</td></tr><tr><td>nicolau.duransilva@sirisacademic.com</td><td>5c339fa1-ee1c-46b0-99c7-a2b37711af08</td><td>annotator</td><td>2025-03-27T15:07:48.709459</td></tr><tr><td>hevs</td><td>a66215e0-bec7-45d7-948f-435b78a1dd19</td><td>annotator</td><td>2025-04-02T14:34:51.070135</td></tr><tr><td>siris</td><td>7eb86803-f4b9-4ac3-95bc-e59fa8cfc0f8</td><td>annotator</td><td>2025-04-02T14:34:51.559531</td></tr><tr><td>andrea.salmi</td><td>0c55e31a-e8f5-4179-bc89-1418dcdb3d6a</td><td>annotator</td><td>2025-04-04T15:18:31.828365</td></tr><tr><td>jakob.rager</td><td>b56829a4-d33d-40e1-bcd6-2a3fc66bd7c7</td><td>annotator</td><td>2025-04-04T15:18:32.276730</td></tr><tr><td>jens.ingensand</td><td>5dcd7453-5bde-41d8-b20c-696a9d883d5f</td><td>annotator</td><td>2025-04-04T15:18:32.669602</td></tr><tr><td>affilgood_el</td><td>79ffeab3-44f5-429c-8071-b724120e2baf</td><td>annotator</td><td>2025-04-08T15:11:35.659686</td></tr><tr><td>xkitsios</td><td>2336fe77-1981-4e9e-a5c8-1914631ad898</td><td>annotator</td><td>2025-04-11T08:40:06.638040</td></tr><tr><td>athanasios.ballis</td><td>4b8c3fe0-5d19-47b2-b4b5-276e7f0356d0</td><td>annotator</td><td>2025-04-11T08:40:07.030150</td></tr><tr><td>a.anagnostopoulou</td><td>5244b90e-8a57-437e-bf2e-4a5f4d5e7456</td><td>annotator</td><td>2025-04-11T08:44:58.849387</td></tr><tr><td>test.user</td><td>77397117-5ed6-4931-bd9b-0fb2fe5624e5</td><td>annotator</td><td>2025-04-11T08:56:19.301718</td></tr><tr><td>cesar.parra@sirisacademic.com</td><td>1b090c2c-bac3-4200-bb72-f0e5c2287202</td><td>annotator</td><td>2025-04-24T16:49:09.727606</td></tr><tr><td>lucien.troillet</td><td>126aa856-31dd-41e9-8688-003b63bdf236</td><td>annotator</td><td>2025-04-29T10:28:45.400509</td></tr><tr><td>martine.besse</td><td>407cf5a9-5d30-4a31-9d74-52216865c2f6</td><td>annotator</td><td>2025-04-29T10:28:45.746618</td></tr><tr><td>archana.golla</td><td>3c769fcb-8d37-41a2-b5e3-943a2a1090ab</td><td>annotator</td><td>2025-04-29T15:00:01.813073</td></tr><tr><td>ingrid.reiten</td><td>cbe332d3-f22d-4e25-9125-2bbc3db1f807</td><td>annotator</td><td>2025-04-29T15:00:02.162873</td></tr><tr><td>ismaelrafols@gmail.com</td><td>144a9005-1f5c-4aa9-9770-e3bfab863e51</td><td>annotator</td><td>2025-05-05T13:33:05.006069</td></tr><tr><td>rcostas@cwts.leidenuniv.nl</td><td>ed61ad17-d431-402f-881a-bd7c7de14ca6</td><td>annotator</td><td>2025-05-05T13:33:05.393693</td></tr><tr><td>leily.rabbani</td><td>5b43cb5b-db52-4fc7-b5a6-a2a0c83cc27f</td><td>annotator</td><td>2025-05-16T10:14:12.033178</td></tr><tr><td>konstantinos.kardamiliotis</td><td>402f3b0e-a9d6-4eb0-bf75-9c313d346482</td><td>annotator</td><td>2025-05-16T10:14:12.407577</td></tr><tr><td>legraet.youna@gmail.com</td><td>3cc38c4a-22ef-4507-bae8-cf63aac5c625</td><td>annotator</td><td>2025-05-16T18:21:39.465614</td></tr><tr><td>maria.apostolaki@gmail.com</td><td>cc41c71e-aebb-419f-b53e-c3a1ea61f536</td><td>annotator</td><td>2025-05-16T18:21:40.007431</td></tr><tr><td>maria.caldero@uvic.cat</td><td>d1e91f94-bf69-4261-b875-ec18a5d916d4</td><td>annotator</td><td>2025-05-16T18:21:40.429459</td></tr><tr><td>chaimaeessousi@gencat.cat</td><td>343bb41a-1e77-4d7f-824b-8239b7a161cb</td><td>annotator</td><td>2025-05-16T18:21:40.897450</td></tr><tr><td>stefano.valentini@art-er.it</td><td>fcccd08c-e7b2-4c1a-b6a5-9341c0feb358</td><td>annotator</td><td>2025-05-16T18:21:41.438542</td></tr><tr><td>enric.fuster@sirisacademic.com</td><td>4cd9635e-4d6f-4a25-8b44-b854abc8d31d</td><td>annotator</td><td>2025-05-16T18:21:41.867696</td></tr><tr><td>theodore.hervieux@sirisacademic.com</td><td>5acaa4d7-ef5d-40b4-a8e4-0ccc689d32b0</td><td>annotator</td><td>2025-05-16T18:21:42.299976</td></tr><tr><td>elisabetta.marinelli@sirisacademic.com</td><td>fef7bfd2-c31b-4f38-a3cc-ca8d02047817</td><td>annotator</td><td>2025-05-16T18:21:42.736832</td></tr><tr><td>joao.serta@institutlouisbachelier.org</td><td>344e79a7-5c31-41d4-aa35-0ee4faf3f972</td><td>annotator</td><td>2025-06-04T14:46:13.623406</td></tr><tr><td>nestor.toroman@institutlouisbachelier.org</td><td>c1a5adc6-dd6d-4555-9e54-97c00d4cc5c3</td><td>annotator</td><td>2025-06-04T14:46:15.627208</td></tr></table>"
      ],
      "text/plain": [
       "<argilla.client.Users at 0x7a8baaf1b1f0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define users\n",
    "client.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = client.workspaces('mutomo')\n",
    "\n",
    "# berta\n",
    "user = client.users('berta.grimau@sirisacademic.com')\n",
    "added_user = user.add_to_workspace(workspace)\n",
    "\n",
    "# nicolau\n",
    "user = client.users('nicolau.duransilva@sirisacademic.com')\n",
    "added_user = user.add_to_workspace(workspace)\n",
    "\n",
    "# theodore\n",
    "user = client.users('theodore.hervieux@sirisacademic.com')\n",
    "added_user = user.add_to_workspace(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_argilla = '''benedikt.schmidt@sirisacademic.com\tnOFxeR4M07'''.split('\\n')\n",
    "users_argilla = [item.split('\\t') for item in users_argilla]\n",
    "\n",
    "# adding nico as a user \n",
    "for user_name, user_pswd in users_argilla:\n",
    "    new_user = rg.User(\n",
    "        username=user_name,\n",
    "        password=user_pswd,\n",
    "        role=\"annotator\", \n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    created_user = new_user.create()\n",
    "\n",
    "    user = client.users(user_name)\n",
    "    workspace = client.workspaces('mutomo')\n",
    "\n",
    "    added_user = user.add_to_workspace(workspace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mutomo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
